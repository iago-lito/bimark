# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Here is the very same model as the adjacent one, but adapted for the
# degenerated case where LB == 0. In this case, the polytope has no dimensions,
# and it is difficult to handle it because JAGS doesn't seem to handle empty
# vectors.
# Watch out, this script will probably not work in the super degenerated case
# where LL = LR = LS = 0, but then please don't bother using it: you have no
# data.
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #


# Describe all nodes here: # {{{
var

# First, data nodes: they are fixed # {{{ - - - - - - - - - - - - - - - - - - -
# number of capture occasions
  T,
# number of capture events
  nbCaptureEvents,
# number of various types of histories to consider
# LB should equal zero now, because one of (LL, LR) is zero, so the other equals
# LU and LM.. and may be zero as well (in which case L == LS)
  LS, LL, LR, LU, LB, LM, L,
  jagsS.f[jagsLS], # still handle the LS=0 case with this trick (see main model)
  is.Sf.empty,
# the actual histories
  Omega[L,T],
# In this degenerated model, the latent counts X are constant, equal to the
# observed counts. They are thus given as data: X = c(jagsS.f, L.f, R.f)
  fixed.X[L + is.Sf.empty],
# }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Second, prior "hyper"parameters: they are also fixed # {{{ - - - - - - - - - -
# beta hyperparameters for capture probabilities on each occasion
  h.P[2],
# dirichlet parameters for capture events probabilities given that a capture
# occured (its first element ('no capture') will be set to zero)
  h.delta[nbCaptureEvents],
# }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Third: parameters: these are the ones whose values we are looking for: # {{{ -
# probabilities of capture on each occasion
  P[T],
# probabilities of each capture event given that capture occured
  delta[nbCaptureEvents],
# }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Fourth: intermediate values, just technically helpful # {{{ - - - - - - - - -
# convenience iterator for handling "no S-histories" case in the likelihood-loop
  it[L],
# log-probabilities of each capture event in Omega (for machine accuracy)
  ln.pi.t[L,T],
# Probability of being capture at least once
  G,
# Probabilities of capture, conditionnally that there is any capture at all
  p[T],
# log-probabilities for each capture history (for machine accuracy)
  ln.pi[L],
# log-factors of the likelihood (for machine accuracy)
  ln.Likelihood.f[L],
# log-likelihood (for machine accuracy)
  ln.Likelihood,
# latent number of captured individuals (sum(X) = cst)
  n,
# total estimated number of individuals
  N,
# high constant for the poisson trick:
  PoissonC,
# Probability for PoissonTrick:
  lambda,
# dummy for the poisson trick, given as data to 1
  PoissonTrick;
# }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# }}}


model {


  # Priors on capture parameters: # {{{ - - - - - - - - - - - - - - - - - - - -

  # The probabilities of capture have been assumed to come from a beta
  # distribution
  for (t in 1:T){
    P[t] ~ dbeta(h.P[1], h.P[2])
    p[t] <- P[t] / G
  }
  # And then they are observed:
  G <- 1 - prod(1 - P[])

  # The probabilities of capture events have been assumed to come from a
  # dirichlet distribution:
  delta[] ~ ddirch(h.delta[])

  # }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


  # Likelihood # {{{ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

  # Probabilities of each single capture event in Omega:
  # (conditional on capture)
  for(omega in 1:L){ # iterate on all latent stories
    for(t in 1:T){   # then on all capture occasions
      ln.pi.t[omega, t] <- # the log-probability of this event happening
          step((Omega[omega, t] == 0) - 1) * log(1-p[t]) # *no* capture or..  0
        + step((Omega[omega, t] != 0) - 1) * log(p[t])   # ..*capture*, then: -
        + step((Omega[omega, t] == 1) - 1) * log(delta[2]) # left encounter   L
        + step((Omega[omega, t] == 2) - 1) * log(delta[3]) # right encounter  R
        + step((Omega[omega, t] == 3) - 1) * log(delta[4]) # both encounters  B
        + step((Omega[omega, t] == 4) - 1) * log(delta[5]) # simultaneous     S
    }
    # log-Probability of a latent encounter history:
    ln.pi[omega] <- sum(ln.pi.t[omega,])

    # Correct the iterator if there is an empty S.f, not to take it into account
    it[omega] <- omega + is.Sf.empty

    # Explicit each factor of the total log-likelihood:
    ln.Likelihood.f[omega] <- fixed.X[it[omega]] * ln.pi[omega]
                            - logfact(fixed.X[it[omega]])
  }

  # Poisson trick!
  # Likelihood, formula for the multinomial distribution:
  n <- sum(fixed.X) # this is why the fake `S.f` data, if they exist, must be 0
  ln.Likelihood <- logfact(n) + sum(ln.Likelihood.f[])
                 - n * log(G) - (N - n) * log(1 - G)
  lambda <- PoissonC - ln.Likelihood
  PoissonTrick ~ dpois(lambda)

  # }}} - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -


  # Conclude with our estimation:
  N <- n / G


}

